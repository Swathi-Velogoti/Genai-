{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA6mGKNXw6pt"
      },
      "outputs": [],
      "source": [
        "!pip install langchain -q\n",
        "!pip install openai -q\n",
        "!pip install langchain_community -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import langchain\n",
        "from langchain.llms import OpenAI\n",
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "tv9dqzQUxDiV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "chat = ChatOpenAI(temperature=0.3)"
      ],
      "metadata": {
        "id": "OR0jGK60xUvp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
        "response = chat([\n",
        "SystemMessage(content=\"Yor are a AI assitant with a sense of humor\"),\n",
        "HumanMessage(content=\"I am going out on sunny day, what precautions should i take\")\n",
        "])"
      ],
      "metadata": {
        "id": "yxUI3wPSxUqn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "Q36BI_V_xUjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a07d5d17-0d0a-4674-8058-2307ecb25ea5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Don't forget your sunscreen, sunglasses, and a hat to protect yourself from the sun's rays! And of course, remember to stay hydrated and wear comfortable clothing. Oh, and most importantly, don't forget to bring your fabulous self along for the ride!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 36, 'total_tokens': 89, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ceb13385-e4b0-414e-b7e0-32512a666e91-0')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit app -Simple QnA with Memory\n",
        "\n"
      ],
      "metadata": {
        "id": "Pxpoyx-Uz3ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!pip install -q pyngrok"
      ],
      "metadata": {
        "id": "za8F-D3-zbbu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage,SystemMessage,AIMessage\n",
        "\n",
        "#Langchain function\n",
        "def get_chatmodel_response(question):\n",
        "    os.environ['Test_key'] = 'sk-proj-sk-proj-YOem1WXY7vUSGyu0tl1FKtkzHoYJE5bBm1rJ4EkFWlZFqPCXrmV0UgwiGnln7xawwmzypatEY1T3BlbkFJiZYOPy-ncBudJe0gWhx75W9whW-Ehc3s0sXy6qRytNd_6UjdpSGclvaLLnAw9W88W3WkgYEAA'\n",
        "\n",
        "    chat=ChatOpenAI(temperature=0.5)\n",
        "    st.session_state['flowmessages'].append(HumanMessage(content=question))\n",
        "    answer=chat(st.session_state['flowmessages'])\n",
        "    st.session_state['flowmessages'].append(AIMessage(content=answer.content))\n",
        "    return answer.content\n",
        "\n",
        "\n",
        "\n",
        "## Streamlit UI\n",
        "st.set_page_config(page_title=\"Conversational Q&A Chatbot\")\n",
        "st.header(\"Hi, how can i help you\")\n",
        "\n",
        "if 'flowmessages' not in st.session_state:\n",
        "    st.session_state['flowmessages']=[\n",
        "        SystemMessage(content=\"Yor are an AI assistant with a sense of humor\")\n",
        "    ]\n",
        "\n",
        "input=st.text_input(\"Input: \",key=\"input\")\n",
        "response=get_chatmodel_response(input)\n",
        "\n",
        "submit=st.button(\"Ask a question\")\n",
        "\n",
        "## If ask button is clicked\n",
        "\n",
        "if submit:\n",
        "    st.subheader(\"The Response is\")\n",
        "    st.write(response)"
      ],
      "metadata": {
        "id": "18mB6yndzbZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2df6a6-7117-40db-f6a5-2a842dbeb80b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "#Set auth token\n",
        "ngrok.set_auth_token(\"2vp3J3I8Z0cbcULJt4YGftMirUO_35iWYZ2MatV2TBFgADWt\")\n",
        "\n",
        "!nohup streamlit run app.py --server.port 5011 &\n",
        "# Start ngrok tunnel\n",
        "ngrok_tunnel = ngrok.connect(addr='5011', proto='http', bind_tls=True)\n",
        "\n",
        "# Print the URL\n",
        "print(' * Tunnel URL:', ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "id": "QAYR_snozbV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f64f5dc-003e-411e-88b5-c9f0896ed881"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            " * Tunnel URL: https://2b46-34-16-187-74.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wRkDc7LVzbJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2YU4f-4FxUeV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}